{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6653142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3af3e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Word2Vec\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "027b68f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/17 23:51:42 WARN Utils: Your hostname, MAINFRAME resolves to a loopback address: 127.0.1.1; using 192.168.1.68 instead (on interface wlp3s0)\n",
      "22/12/17 23:51:42 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/17 23:51:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .master('local[1]')\\\n",
    "        .appName('ToxicComment')\\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d16f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('train.csv', sep=',', quote='\\\"', escape='\\\"', multiLine=True, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d52cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train_df, val_df = df.randomSplit(weights=[0.8, 0.2], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ea6b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_result(num_features):\n",
    "    tokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"splitted\")\n",
    "    tf  = HashingTF(inputCol=\"splitted\", outputCol=\"tf_features\", numFeatures=num_features)\n",
    "    idf = IDF(inputCol=\"tf_features\", outputCol=\"idf_features\")\n",
    "    pipeline = Pipeline(stages=[tokenizer, tf, idf])\n",
    "    model = pipeline.fit(train_df)\n",
    "    train_data = model.transform(train_df)\n",
    "    val_data = model.transform(val_df)\n",
    "\n",
    "    res = {}\n",
    "\n",
    "    for label in labels:\n",
    "        classifier = LogisticRegression(featuresCol='idf_features', labelCol=label).fit(train_data)\n",
    "        preds = classifier.transform(val_data).select(col(label).alias(\"label\"), \"prediction\")\n",
    "        metrics = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label', \n",
    "                                                metricName='areaUnderROC')\n",
    "        res[label] = metrics.evaluate(preds)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b068c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF/IDF numFeatures: 100 {'toxic': 0.5259407229136341, 'severe_toxic': 0.5266930305469325, 'obscene': 0.5190325188943047, 'threat': 0.5048839383081477, 'insult': 0.5204514316053923, 'identity_hate': 0.5099313542152994}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF/IDF numFeatures: 150 {'toxic': 0.5441220980779745, 'severe_toxic': 0.5370152345810655, 'obscene': 0.5411554030814869, 'threat': 0.5149945474372956, 'insult': 0.5320253657584176, 'identity_hate': 0.5116518943152326}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1765:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF/IDF numFeatures: 200 {'toxic': 0.5588773195006544, 'severe_toxic': 0.556261273205821, 'obscene': 0.5643436669819449, 'threat': 0.5200965882536221, 'insult': 0.5428172687182542, 'identity_hate': 0.5114637888507688}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for numFeatures in [100, 150, 200]:\n",
    "    res = tf_idf_result(numFeatures)\n",
    "    print(\"TF/IDF numFeatures:\", numFeatures, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde1056f",
   "metadata": {},
   "source": [
    "Для небольшого числа фичей (100) значения AUROC получились небольшими. По мере увеличения параметра значение метрики растет. Целесообразно обучать модель на существенно большем числе фичей (от 1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8ae7d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1776:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/18 00:00:25 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/12/18 00:00:25 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2087:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec metrics: {'toxic': 0.7430592490521165, 'severe_toxic': 0.5853900658050697, 'obscene': 0.7349591492950127, 'threat': 0.5100015578750584, 'insult': 0.6809162912041663, 'identity_hate': 0.5331567655689046}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"splitted\")\n",
    "word2Vec = Word2Vec(vectorSize=40, seed=17, inputCol=\"splitted\", outputCol=\"features\", windowSize=10)\n",
    "pipeline = Pipeline(stages=[tokenizer, word2Vec])\n",
    "model = pipeline.fit(train_df)\n",
    "train_data = model.transform(train_df)\n",
    "val_data = model.transform(val_df)\n",
    "\n",
    "res_w2v = {}\n",
    "\n",
    "for label in labels:\n",
    "    classifier = LogisticRegression(featuresCol='features', labelCol=label).fit(train_data)\n",
    "    preds = classifier.transform(val_data).select(col(label).alias(\"label\"), \"prediction\")\n",
    "    metrics = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label', \n",
    "                                            metricName='areaUnderROC')\n",
    "    res_w2v[label] = metrics.evaluate(preds)\n",
    "\n",
    "print(\"Word2Vec metrics:\", res_w2v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
